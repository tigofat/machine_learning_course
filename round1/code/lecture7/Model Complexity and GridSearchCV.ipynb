{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.521518\n",
      "n_neighbors: 3, average score: 0.739326\n",
      "n_neighbors: 5, average score: 0.745111\n",
      "n_neighbors: 10, average score: 0.762250\n",
      "n_neighbors: 20, average score: 0.541425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f289e146f28>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28a04345c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_errors, test_errors = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_errors.mean(axis=1), label=\"train error\")\n",
    "plt.plot(n_neighbors, test_errors.mean(axis=1), label=\"test error\")\n",
    "plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot is the mirror image of the diagram above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.180600\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.042729\n",
      "C: 0.001000, gamma: 0.100000, average score: 0.002902\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.096822\n",
      "C: 0.010000, gamma: 0.001000, average score: 0.001018\n",
      "C: 0.010000, gamma: 0.010000, average score: 0.021279\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.051228\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.006842\n",
      "C: 0.100000, gamma: 0.001000, average score: 0.006122\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.088318\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.499120\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.463847\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.187498\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.592903\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.610995\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.720848\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.580448\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.623553\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.627132\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.748434\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=1, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'gamma': [0.001, 0.01, 0.1, 1], 'C': [0.001, 0.01, 0.1, 1, 10]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7122609121436073\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gamma': 1, 'C': 10}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
